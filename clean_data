import re
import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from textblob import TextBlob

# Load Spacy NLP model
nlp = spacy.load("en_core_web_sm")

# Contraction mapping (example, can be expanded)
contraction_mapping = {"isn't": "is not", "aren't": "are not"}  # Add more contractions as needed

def expand_contractions(text, contraction_mapping):
    """
    Expand contractions in the text based on a mapping dictionary.
    """
    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), flags=re.IGNORECASE)
    def expand_match(contraction):
        match = contraction.group(0)
        first_char = match[0]
        expanded_contraction = contraction_mapping.get(match.lower() if contraction_mapping.get(match.lower()) else match)
        return first_char + expanded_contraction[1:]
    expanded_text = contractions_pattern.sub(expand_match, text)
    return expanded_text

def remove_punctuation(text):
    """
    Remove punctuation from the text.
    """
    return re.sub(r'[^\w\s]', '', text)

def apply_custom_normalization_rules(text, rules):
    """
    Apply custom normalization rules to the text.
    """
    for old, new in rules.items():
        text = text.replace(old, new)
    return text

def preserve_named_entities(original_text, cleaned_text):
    """
    Preserve named entities in the cleaned text.
    """
    doc = nlp(original_text)
    entities = {ent.text: ent.label_ for ent in doc.ents}
    for entity in entities.keys():
        cleaned_text = cleaned_text.replace(entity.lower(), entity)
    return cleaned_text

def clean_data(text, remove_punctuation=True, lowercase=True, remove_stopwords=False, correct_spelling=False, custom_stopwords=[], handle_special_characters='remove', expand_contractions=False, preserve_entities=False, custom_normalization_rules={}):
    """
    Enhances text cleaning and preprocessing with added functionalities.
    """
    original_text = text
    text = apply_custom_normalization_rules(text, custom_normalization_rules)
    
    if lowercase:
        text = text.lower()
    
    if remove_punctuation:
        text = remove_punctuation(text)
    
    if expand_contractions:
        text = expand_contractions(text, contraction_mapping)
    
    if remove_stopwords or custom_stopwords:
        stopwords = set(STOP_WORDS).union(set(custom_stopwords))
        text = " ".join([word for word in text.split() if word not in stopwords])
    
    if correct_spelling:
        text = str(TextBlob(text).correct())
    
    if handle_special_characters != 'keep':
        replacement = '' if handle_special_characters == 'remove' else ' REPLACEMENT '
        text = re.sub(r'[\W_]+', replacement, text)
    
    if preserve_entities:
        text = preserve_named_entities(original_text, text)
    
    return text

# Example usage
sample_text = "Hello, world! This is a test. AI is amazing, isn't it? ðŸš€"
custom_stopwords = ['this', 'is']
custom_normalization_rules = {'AI': 'Artificial Intelligence'}

cleaned_text = clean_data(sample_text, expand_contractions=True, preserve_entities=True, custom_stopwords=custom_stopwords, handle_special_characters='replace', custom_normalization_rules=custom_normalization_rules)
print(cleaned_text)
